{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90861ecd",
   "metadata": {},
   "source": [
    "\n",
    "# IFN580 – Assignment 1: Starter Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8812c4",
   "metadata": {},
   "source": [
    "## 1) Config & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Config & Imports\n",
    "RANDOM_STATE = 42\n",
    "TARGET_COL = \"IsBadBuy\"  # change if your target column differs\n",
    "\n",
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Ensure inline plots in classic Notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa679fd1",
   "metadata": {},
   "source": [
    "## 2) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d25247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load Data (robust search + sentinel handling)\n",
    "DATA_PATHS = [\n",
    "    \"data/kick.csv\",\n",
    "    \"kick.csv\",\n",
    "    \"assignment 1 data kick.csv\",\n",
    "    \"./data/kick.csv\",\n",
    "]\n",
    "\n",
    "def find_data(paths):\n",
    "    for p in paths:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "DATA_PATH = find_data(DATA_PATHS)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"CSV not found. Put your dataset as 'data/kick.csv' or update DATA_PATHS.\")\n",
    "\n",
    "print(f\"Using data at: {DATA_PATH}\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Turn '?' into NaN so imputers treat them as missing\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "print(df.shape)\n",
    "display(df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b90fed",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Quick Audit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcafe21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3) Quick Audit + numeric coercion (promote numeric-like object columns)\n",
    "\n",
    "# Convert object columns that look numeric into real numbers (heuristic)\n",
    "coerced = []\n",
    "for c in df.columns:\n",
    "    if c == TARGET_COL:  # don't touch the target\n",
    "        continue\n",
    "    s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    # treat as numeric if majority converts and at least some support\n",
    "    if (s.notna().mean() > 0.6) and (s.notna().sum() > 100):\n",
    "        df[c] = s\n",
    "        coerced.append(c)\n",
    "print(\"Coerced to numeric:\", len(coerced), \"| sample:\", coerced[:8])\n",
    "\n",
    "# Basic info for Task 1 evidence\n",
    "display(df.info())\n",
    "print(\"Target counts (before):\")\n",
    "display(df[TARGET_COL].value_counts(dropna=False))\n",
    "print(\"Target ratio (before):\")\n",
    "display(df[TARGET_COL].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648b0d6-7001-46c6-8bfb-19a334b6aea2",
   "metadata": {},
   "source": [
    "## 4)Train/Test Split (stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce7759-dfdf-48e8-982e-343729f1a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Train/Test Split (stratified) and drop non-predictive columns\n",
    "drop_cols = [c for c in [\"PurchaseID\", \"PurchaseDate\"] if c in df.columns]  # keep PurchaseTimestamp\n",
    "\n",
    "y = df[TARGET_COL]\n",
    "X = df.drop(columns=[TARGET_COL] + drop_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train/Test sizes:\", X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab23d02-bf50-469d-8a1b-b80632653e71",
   "metadata": {},
   "source": [
    "## 5) Preprocessing Pipeline (ColumnTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53195c37-3e96-4eae-b482-efe1dcc1928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Preprocessing Pipeline (ColumnTransformer) – sklearn-version safe\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X_train.columns.difference(numeric_features).tolist()\n",
    "\n",
    "# Numeric: impute median then standardize (dense)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical: impute mode then One-Hot Encode\n",
    "# Guard for sklearn param rename: 'sparse' (old) -> 'sparse_output' (new)\n",
    "try:\n",
    "    _ = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", ohe)\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "print(\"Numeric features:\", len(numeric_features))\n",
    "print(\"Categorical features:\", len(categorical_features))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
